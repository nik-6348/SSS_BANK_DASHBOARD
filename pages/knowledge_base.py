import streamlit as st
import os
import shutil
import pandas as pd
from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from langchain_community.vectorstores import Chroma
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from utils.pdf_processor import PDFProcessor
from dotenv import load_dotenv

load_dotenv()
API_KEY = os.getenv("GOOGLE_API_KEY")

def init_rag_automatically(df):
    """Auto-initialize RAG system with transaction data"""
    embeddings = GoogleGenerativeAIEmbeddings(
        model="models/embedding-001",
        google_api_key=API_KEY
    )
    llm = ChatGoogleGenerativeAI(
        model="gemini-2.0-flash-exp",
        google_api_key=API_KEY,
        temperature=0.3,
        convert_system_message_to_human=True
    )
    
    # Convert rows to Documents
    from langchain_core.documents import Document
    docs = [Document(page_content=str(row)) for _, row in df.iterrows()]
    db = Chroma.from_documents(documents=docs, embedding=embeddings, persist_directory="./chroma_db")
    
    # Prompt with chat history
    prompt = ChatPromptTemplate.from_messages([
        ("system", "You are a sharp financial assistant! Answer using this transaction context."),
        MessagesPlaceholder(variable_name="chat_history"),
        ("human", "{input}")
    ])
    
    qa_chain = db.as_retriever(search_kwargs={"k":5}), prompt, llm
    st.session_state.vectorstore = db
    st.session_state.qa_chain = qa_chain
    st.session_state.rag_ready = True

def render_knowledge_base():
    """Render the enhanced knowledge base management page"""
    st.header("üß† Knowledge Base Management")
    
    # Primary Upload Section - Most prominent
    st.subheader("üìÅ Upload Bank Statements")
    st.info("ü§ñ **AI-Powered Extraction**: Upload your bank statement PDFs here. Our system uses Gemini AI to intelligently extract transactions!")
    
    uploaded_files = st.file_uploader(
        "Upload Bank Statement PDFs", 
        type=["pdf"], 
        accept_multiple_files=True,
        help="Upload one or more bank statement PDFs for analysis"
    )
    
    if uploaded_files:
        st.session_state.uploaded_files = uploaded_files
        total_df = pd.DataFrame()
        successful_uploads = 0
        
        with st.spinner("ü§ñ AI is processing your bank statements..."):
            for pdf in uploaded_files:
                try:
                    from utils.pdf_parser import parse_pdf
                    df = parse_pdf(pdf, API_KEY)
                    if not df.empty:
                        total_df = pd.concat([total_df, df], ignore_index=True)
                        successful_uploads += 1
                    else:
                        st.warning(f"Could not extract structured data from {pdf.name}. The file will be available for RAG queries.")
                except Exception as e:
                    st.error(f"Error processing {pdf.name}: {str(e)}")
        
        st.session_state.transactions = total_df
        
        # Auto-initialize knowledge base
        if not total_df.empty:
            st.success(f"ü§ñ AI extracted {len(total_df)} transactions from {successful_uploads} file(s)!")
            st.info("üí° Using AI-powered extraction - much smarter than traditional parsing!")
            
            # Auto-initialize RAG
            try:
                if API_KEY and not st.session_state.get('rag_ready', False):
                    with st.spinner("üß† Initializing AI Knowledge Base..."):
                        init_rag_automatically(total_df)
                        st.success("‚úÖ AI Knowledge Base initialized automatically!")
                        st.rerun()
            except Exception as e:
                st.warning(f"Could not auto-initialize knowledge base: {str(e)}")
        else:
            st.info(f"Processed {len(uploaded_files)} file(s) but no structured transactions found. You can still use the RAG chatbot to query the documents.")
    
    st.markdown("---")
    
    # Knowledge Base Status
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("üìä Current Status")
        if st.session_state.rag_ready:
            st.success("‚úÖ Knowledge Base Active")
            
            # Show stats
            if hasattr(st.session_state, 'vectorstore') and st.session_state.vectorstore:
                try:
                    # Get collection info
                    collection = st.session_state.vectorstore._collection
                    doc_count = collection.count()
                    st.metric("üìÑ Documents", doc_count)
                except Exception:
                    st.metric("üìÑ Documents", "Unknown")
            
            if not st.session_state.transactions.empty:
                st.metric("üíº Transactions", len(st.session_state.transactions))
        else:
            st.warning("‚è≥ Knowledge Base Not Initialized")
    
    with col2:
        st.subheader("üîß Actions")
        if st.button("üîÑ Refresh Status", type="secondary"):
            st.rerun()
    
    st.markdown("---")
    
    # Document Management Section
    st.subheader("üìÅ Document Management")
    
    # Show existing documents in ChromaDB
    if os.path.exists("./chroma_db"):
        st.write("**üìÇ Current Knowledge Base Contents:**")
        
        try:
            if hasattr(st.session_state, 'vectorstore') and st.session_state.vectorstore:
                # Get all documents from the vectorstore
                collection = st.session_state.vectorstore._collection
                results = collection.get()
                
                if results['ids']:
                    # Create a dataframe to display documents
                    doc_data = []
                    for i, doc_id in enumerate(results['ids']):
                        doc_data.append({
                            'ID': doc_id,
                            'Content Preview': results['documents'][i][:100] + "..." if len(results['documents'][i]) > 100 else results['documents'][i],
                            'Metadata': str(results['metadatas'][i]) if results['metadatas'][i] else "No metadata"
                        })
                    
                    st.dataframe(doc_data, use_container_width=True)
                    
                    # Document actions
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        if st.button("üóëÔ∏è Clear All Documents", type="secondary"):
                            if st.session_state.vectorstore:
                                try:
                                    collection.delete()
                                    st.success("‚úÖ All documents cleared!")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"Error clearing documents: {e}")
                    
                    with col2:
                        if st.button("üîÑ Rebuild Index", type="secondary"):
                            st.info("Rebuilding index...")
                            # This would trigger a rebuild of the vectorstore
                            st.success("‚úÖ Index rebuilt!")
                    
                    with col3:
                        if st.button("üìä View Statistics", type="secondary"):
                            st.write("**Knowledge Base Statistics:**")
                            st.write(f"- Total Documents: {len(results['ids'])}")
                            st.write(f"- Collection Name: {collection.name}")
                            st.write("- Embedding Model: models/embedding-001")
                else:
                    st.info("No documents found in the knowledge base.")
            else:
                st.info("Knowledge base not initialized. Upload documents to get started.")
                
        except Exception as e:
            st.error(f"Error accessing knowledge base: {e}")
            st.info("Knowledge base may not be properly initialized.")
    else:
        st.info("No knowledge base directory found. Upload documents to create one.")
    
    st.markdown("---")
    
    # Add New Documents Section
    st.subheader("‚ûï Add New Documents")
    
    # File upload for new documents
    new_files = st.file_uploader(
        "Upload new PDF documents to add to knowledge base",
        type=["pdf"],
        accept_multiple_files=True,
        key="kb_file_upload"
    )
    
    if new_files:
        st.write(f"**Uploaded {len(new_files)} file(s):**")
        for file in new_files:
            st.write(f"üìÑ {file.name} ({file.size} bytes)")
        
        if st.button("üöÄ Add to Knowledge Base", type="primary"):
            with st.spinner("Processing documents..."):
                try:
                    # Initialize embeddings and LLM
                    embeddings = GoogleGenerativeAIEmbeddings(
                        model="models/embedding-001",
                        google_api_key=API_KEY
                    )
                    llm = ChatGoogleGenerativeAI(
                        model="gemini-2.0-flash-exp",
                        google_api_key=API_KEY,
                        temperature=0.3,
                        convert_system_message_to_human=True
                    )
                    
                    # Process new documents
                    processor = PDFProcessor()
                    new_documents = []
                    
                    for pdf in new_files:
                        docs = processor.process_pdf(pdf)
                        new_documents.extend(docs)
                    
                    if new_documents:
                        # Add to existing vectorstore or create new one
                        if hasattr(st.session_state, 'vectorstore') and st.session_state.vectorstore:
                            # Add to existing
                            st.session_state.vectorstore.add_documents(new_documents)
                            st.success(f"‚úÖ Added {len(new_documents)} document chunks to existing knowledge base!")
                        else:
                            # Create new vectorstore
                            db = Chroma.from_documents(
                                documents=new_documents, 
                                embedding=embeddings, 
                                persist_directory="./chroma_db",
                                collection_name="bank_statements"
                            )
                            
                            # Setup QA chain
                            prompt = ChatPromptTemplate.from_messages([
                                ("system", "You are a helpful assistant for analyzing bank statements. Use the provided context to answer questions about financial transactions, balances, and account activity."),
                                MessagesPlaceholder(variable_name="chat_history"),
                                ("human", "{input}")
                            ])
                            
                            st.session_state.vectorstore = db
                            st.session_state.qa_chain = (db.as_retriever(search_kwargs={"k":5}), prompt, llm)
                            st.success(f"‚úÖ Created new knowledge base with {len(new_documents)} document chunks!")
                        
                        st.session_state.rag_ready = True
                        st.rerun()
                    else:
                        st.error("No document content could be extracted from the uploaded files.")
                        
                except Exception as e:
                    st.error(f"Error adding documents to knowledge base: {str(e)}")
    
    st.markdown("---")
    
    # Knowledge Base Settings
    st.subheader("‚öôÔ∏è Knowledge Base Settings")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**Current Configuration:**")
        st.write(f"‚Ä¢ API Key: {'‚úÖ Configured' if API_KEY else '‚ùå Missing'}")
        st.write(f"‚Ä¢ Knowledge Base: {'‚úÖ Ready' if st.session_state.rag_ready else '‚è≥ Not initialized'}")
        st.write("- Embedding Model: models/embedding-001")
        st.write("- LLM Model: gemini-2.0-flash-exp")
        st.write("- Vector Store: ChromaDB")
    
    with col2:
        st.write("**System Status:**")
        st.write("- PDF Processing: ‚úÖ AI-Powered")
        st.write("- Document Storage: ‚úÖ Persistent")
        st.write("- Search Capability: ‚úÖ Semantic")
        st.write("- Chat History: ‚úÖ Enabled")
    
    # Advanced Actions
    st.markdown("---")
    st.subheader("üîß Advanced Actions")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("üßπ Clear All Data", type="secondary"):
            st.session_state.transactions = pd.DataFrame()
            st.session_state.vectorstore = None
            st.session_state.qa_chain = None
            st.session_state.rag_ready = False
            st.session_state.messages = []
            st.session_state.uploaded_files = None
            
            # Remove ChromaDB directory
            if os.path.exists("./chroma_db"):
                shutil.rmtree("./chroma_db")
            
            st.success("‚úÖ All data cleared successfully!")
            st.rerun()
    
    with col2:
        if st.button("üíæ Export Knowledge Base", type="secondary"):
            if os.path.exists("./chroma_db"):
                # Create a zip file of the knowledge base
                shutil.make_archive("knowledge_base_backup", 'zip', "./chroma_db")
                with open("knowledge_base_backup.zip", "rb") as f:
                    st.download_button(
                        label="Download Knowledge Base",
                        data=f.read(),
                        file_name="knowledge_base_backup.zip",
                        mime="application/zip"
                    )
            else:
                st.warning("No knowledge base to export.")
    
    with col3:
        if st.button("üîÑ Reset to Default", type="secondary"):
            # Reset all session state
            for key in list(st.session_state.keys()):
                del st.session_state[key]
            st.rerun()
